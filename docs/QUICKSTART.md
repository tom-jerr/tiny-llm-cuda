# å¿«é€Ÿå…¥é—¨æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹ MiniInfer é¡¹ç›®ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

### ç¡¬ä»¶è¦æ±‚

- **CPU**: ä»»æ„ç°ä»£ CPU
- **GPU**: NVIDIA GPU with CUDA support (æ¨è 8GB+ æ˜¾å­˜)
  - æœ€å°: GTX 1060 6GB (ä»…æ”¯æŒå°æ¨¡å‹)
  - æ¨è: RTX 3090, A100, H100
- **å†…å­˜**: 16GB+ RAM

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è), Windows (WSL2), macOS (ä»… CPU)
- **Python**: 3.10, 3.11, æˆ– 3.12
- **CUDA**: 11.8+ (ç”¨äº GPU åŠ é€Ÿ)
- **Git**: ç‰ˆæœ¬æ§åˆ¶

## ğŸš€ å¿«é€Ÿå¼€å§‹ (5 åˆ†é’Ÿ)

### æ­¥éª¤ 1: å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/tom-jerr/MiniInfer .git
cd MiniInfer
```

### æ­¥éª¤ 2: å®‰è£…ä¾èµ–

**é€‰é¡¹ A: ä½¿ç”¨ PDM (æ¨è)**

```bash
# å®‰è£… PDM
pip install pdm

# å®‰è£…é¡¹ç›®ä¾èµ–
pdm install
```

**é€‰é¡¹ B: ä½¿ç”¨ pip**

```bash
pip install torch>=2.6.0 transformers>=4.51.0 accelerate>=1.11.0
pip install flash-attn>=2.8.3  # å¯é€‰ï¼Œç”¨äº Flash Attention
```

### æ­¥éª¤ 3: è¿è¡Œç¬¬ä¸€ä¸ªç¤ºä¾‹

```bash
# ä½¿ç”¨ PDM
pdm run main --model Qwen/Qwen2-1.5B --prompt "Hello, how are you?"

# æˆ–ç›´æ¥ä½¿ç”¨ Python
python main.py --model Qwen/Qwen2-1.5B --prompt "Hello, how are you?"
```

ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 3GBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

## ğŸ’¡ åŸºç¡€ä½¿ç”¨

### 1. å•ä¸ªè¯·æ±‚æ¨ç†

#### ç®€å•ç”Ÿæˆï¼ˆæ—  KV Cacheï¼‰

```bash
python main.py \
  --model Qwen/Qwen2-1.5B \
  --loader v1 \
  --prompt "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
```

#### ä½¿ç”¨ KV Cache åŠ é€Ÿ

```bash
python main.py \
  --model Qwen/Qwen2-1.5B \
  --loader v2 \
  --prompt "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
```

**æ€§èƒ½å¯¹æ¯”**: KV Cache å¯ä»¥æå‡ 3-5x ç”Ÿæˆé€Ÿåº¦ï¼

### 2. æ‰¹å¤„ç†æ¨ç†

```bash
python batch-main.py \
  --model Qwen/Qwen2-0.5B-Instruct \
  --batch-size 5 \
  --prefill-step 128 \
  --max-seq-len 512 \
  --max-new-tokens 100
```

### 3. è‡ªå®šä¹‰é‡‡æ ·å‚æ•°

```bash
python main.py \
  --model Qwen/Qwen2-1.5B \
  --prompt "Tell me a story" \
  --sampler-temp 0.8 \
  --sampler-top-p 0.95 \
  --sampler-top-k 50
```

**å‚æ•°è¯´æ˜**:

- `--sampler-temp`: æ¸©åº¦å‚æ•°ï¼Œè¶Šé«˜è¾“å‡ºè¶Šéšæœº (0.0-2.0)
- `--sampler-top-p`: Nucleus sampling é˜ˆå€¼ (0.0-1.0)
- `--sampler-top-k`: Top-K sampling æ•°é‡

### 4. ä½¿ç”¨ä¸åŒæ¨¡å‹

```bash
# Qwen2 0.5B (æœ€å¿«ï¼Œé€‚åˆæµ‹è¯•)
python main.py --model Qwen/Qwen2-0.5B-Instruct

# Qwen2 1.5B (å¹³è¡¡)
python main.py --model Qwen/Qwen2-1.5B

# Qwen2 7B (éœ€è¦ 16GB+ æ˜¾å­˜)
python main.py --model Qwen/Qwen2-7B
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

### è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
pdm run test
# æˆ–
python scripts/dev-tools.py test
```

### è¿è¡Œç‰¹å®šæµ‹è¯•

```bash
# æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶
python tests/test_attention.py

# æµ‹è¯• Qwen2 æ¨¡å‹
python tests/test_qwen2.py

# æµ‹è¯•æ‰¹å¤„ç†
python tests/test_batching.py

# æµ‹è¯• GQA
python tests/test_gqa.py

# æµ‹è¯• RoPE
python tests/test_rope.py
```

## ğŸ“š å­¦ä¹ ç¤ºä¾‹

é¡¹ç›®æä¾›äº†è¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œå¸®åŠ©ç†è§£å„ä¸ªç»„ä»¶ï¼š

### æ¿€æ´»å‡½æ•°ç¤ºä¾‹

```bash
python examples/activation_usage.py
```

ä½ å°†å­¦åˆ°ï¼š

- å¦‚ä½•ä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°
- æ¿€æ´»å‡½æ•°çš„ç»Ÿä¸€æ¥å£
- åœ¨æ¨¡å‹ä¸­é›†æˆæ¿€æ´»å‡½æ•°

### æ³¨æ„åŠ›æœºåˆ¶ç¤ºä¾‹

```bash
python examples/attention_usage.py
```

ä½ å°†å­¦åˆ°ï¼š

- MHA å’Œ GQA çš„ä½¿ç”¨
- å¦‚ä½•åˆ‡æ¢ä¸åŒçš„æ³¨æ„åŠ›å®ç°
- å› æœé®ç½©çš„åº”ç”¨

## ğŸ”§ å¼€å‘å·¥å…·

### ä»£ç æ ¼å¼åŒ–

```bash
pdm run format
```

ä½¿ç”¨ Ruff æ ¼å¼åŒ–æ‰€æœ‰ Python ä»£ç ã€‚

### æ„å»º CUDA æ‰©å±•

```bash
# æ„å»ºæ‰©å±•
pdm run build-ext

# æµ‹è¯•æ‰©å±•
pdm run build-ext-test

# æ¸…ç†æ„å»ºæ–‡ä»¶
pdm run clean-ext
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ä¸‹è½½æ¨¡å‹å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
python main.py --model Qwen/Qwen2-1.5B
```

### Q2: CUDA Out of Memory é”™è¯¯

**A**: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š

1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆ0.5B è€Œä¸æ˜¯ 7Bï¼‰
2. å‡å°‘æ‰¹å¤„ç†å¤§å°
3. å‡å°‘ `max-seq-len`

```bash
python batch-main.py \
  --model Qwen/Qwen2-0.5B-Instruct \
  --batch-size 2 \
  --max-seq-len 256
```

### Q3: Flash Attention å®‰è£…å¤±è´¥

**A**: Flash Attention æ˜¯å¯é€‰ä¾èµ–ï¼Œå®‰è£…å¤±è´¥ä¸å½±å“åŸºç¡€åŠŸèƒ½ï¼š

```bash
# è·³è¿‡ flash-attn å®‰è£…
pip install torch transformers accelerate
```

æˆ–ä½¿ç”¨é¢„ç¼–è¯‘è½®å­ï¼š

```bash
pip install flash-attn --no-build-isolation
```

### Q4: Windows ä¸Šå¦‚ä½•è¿è¡Œï¼Ÿ

**A**: æ¨èä½¿ç”¨ WSL2ï¼š

1. å®‰è£… WSL2 å’Œ Ubuntu
2. åœ¨ WSL2 ä¸­å®‰è£… CUDA
3. æŒ‰ç…§ Linux æ­¥éª¤å®‰è£…é¡¹ç›®

### Q5: å¦‚ä½•ä½¿ç”¨ CPU è¿è¡Œï¼Ÿ

**A**: æ·»åŠ  `--device cpu` å‚æ•°ï¼š

```bash
python main.py --model Qwen/Qwen2-0.5B --device cpu
```

æ³¨æ„ï¼šCPU æ¨ç†é€Ÿåº¦ä¼šå¾ˆæ…¢ã€‚

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ KV Cache

```bash
# æ…¢ (10 tokens/s)
python main.py --loader v1

# å¿« (30-50 tokens/s)
python main.py --loader v2
```

### 2. æ‰¹å¤„ç†æ¨ç†

æ‰¹å¤„ç†å¯ä»¥æå‡ååé‡ï¼š

```bash
python batch-main.py --batch-size 5  # 4x ååé‡æå‡
```

### 3. ä½¿ç”¨ FP16

é»˜è®¤ä½¿ç”¨ FP16ï¼Œé€Ÿåº¦å¿«ä¸”å†…å­˜å ç”¨å°ã€‚

### 4. è°ƒæ•´ Prefill æ­¥é•¿

```bash
# å°æ­¥é•¿: æ›´çµæ´»ï¼Œä½†å¯èƒ½æ›´æ…¢
python batch-main.py --prefill-step 64

# å¤§æ­¥é•¿: æ›´å¿«ï¼Œä½†çµæ´»æ€§é™ä½
python batch-main.py --prefill-step 256
```

## ğŸ¯ ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å·²ç»æŒæ¡äº†åŸºç¡€ä½¿ç”¨ï¼Œå¯ä»¥ï¼š

1. **æ·±å…¥å­¦ä¹ **: é˜…è¯» [README.md](./README.md) äº†è§£æ¶æ„è®¾è®¡
2. **è´¡çŒ®ä»£ç **: æŸ¥çœ‹ [CONTRIBUTING.md](./CONTRIBUTING.md) å’Œ [ROADMAP.md](./ROADMAP.md)
3. **æ¢ç´¢ä»£ç **: é˜…è¯» `src/` ç›®å½•ä¸‹çš„æºç å’Œæ³¨é‡Š
4. **å®éªŒä¼˜åŒ–**: å°è¯•å®ç° ROADMAP ä¸­çš„åŠŸèƒ½

## ğŸ“– æ¨èé˜…è¯»

- [é¡¹ç›®æ¶æ„è¯´æ˜](./README.md#æ¶æ„)
- [å¼€å‘è·¯çº¿å›¾](./ROADMAP.md)
- [è´¡çŒ®æŒ‡å—](./CONTRIBUTING.md)
- [API æ–‡æ¡£](./docs/)

## ğŸ’¬ è·å¾—å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ

- æŸ¥çœ‹ [Issues](https://github.com/tom-jerr/MiniInfer /issues)
- æé—®åœ¨ [Discussions](https://github.com/tom-jerr/MiniInfer /discussions)
- å‘é€é‚®ä»¶è‡³ tomlzy213@gmail.com

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰

å¦‚æœè§‰å¾—é¡¹ç›®æœ‰å¸®åŠ©ï¼Œåˆ«å¿˜äº†ç»™ä¸ª â­ï¸ Starï¼
