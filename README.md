# MiniInfer

<div align="center">

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**ä¸€ä¸ªä»é›¶å¼€å§‹æ„å»ºçš„è½»é‡çº§é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“**

[ç‰¹æ€§](#ç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [æ¶æ„](#æ¶æ„) â€¢ [ç¤ºä¾‹](#ç¤ºä¾‹) â€¢ [æ–‡æ¡£](#æ–‡æ¡£)

</div>

---

## ğŸ“ é¡¹ç›®ç®€ä»‹

MiniInfer æ˜¯ä¸€ä¸ªå­¦ä¹ æ€§è´¨çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“ï¼Œä»é›¶å®ç°äº†ç°ä»£ LLM æ¨ç†ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ã€‚æœ¬é¡¹ç›®æ—¨åœ¨å¸®åŠ©å¼€å‘è€…æ·±å…¥ç†è§£ LLM æ¨ç†çš„åº•å±‚æœºåˆ¶ï¼ŒåŒ…æ‹¬æ³¨æ„åŠ›æœºåˆ¶ã€KV ç¼“å­˜ã€æ‰¹å¤„ç†è°ƒåº¦ç­‰å…³é”®æŠ€æœ¯ã€‚

### æ ¸å¿ƒç›®æ ‡

- âš¡ **æ€§èƒ½ä¼˜åŒ–**ï¼šå®ç°ä¸»æµæ¨ç†ä¼˜åŒ–æŠ€æœ¯
- ğŸ”§ **æ˜“äºæ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ·»åŠ æ–°åŠŸèƒ½
- ğŸ“š **å®Œæ•´å®ç°**ï¼šä»åŸºç¡€ç®—å­åˆ°å®Œæ•´æ¨ç†æµç¨‹

## âœ¨ ç‰¹æ€§

### å·²å®ç°åŠŸèƒ½

#### ğŸ§  æ ¸å¿ƒç»„ä»¶

- âœ… **æ³¨æ„åŠ›æœºåˆ¶**
  - Multi-Head Attention (MHA)
  - Grouped Query Attention (GQA)
  - æ”¯æŒå› æœæ©ç  (Causal Mask)

- âœ… **ä½ç½®ç¼–ç **
  - Rotary Position Embedding (RoPE)
  - æ”¯æŒä¼ ç»Ÿå’Œéä¼ ç»Ÿæ¨¡å¼ï¼ˆQwen2 ä½¿ç”¨ non-tranditionalï¼‰

- âœ… **æ¿€æ´»å‡½æ•°**

- âœ… **å½’ä¸€åŒ–å±‚**
  - RMSNorm

#### ğŸš€ æ¨ç†ä¼˜åŒ–

- âœ… **KV Cache**
  - å•è¯·æ±‚ KV Cache
  - æ‰¹å¤„ç† KV Cache (å°¾éƒ¨å¯¹é½)
  - æ”¯æŒåŠ¨æ€è¯·æ±‚ç®¡ç†

- âœ… **æ‰¹å¤„ç†æ¨ç†**
  - Continuous Batching
  - åŠ¨æ€è¯·æ±‚è°ƒåº¦
  - æ”¯æŒå¤šè¯·æ±‚å¹¶å‘

- âœ… **CUDA æ‰©å±•**
  - C++/CUDA è‡ªå®šä¹‰ç®—å­
  - PyTorch C++ æ‰©å±•æ¡†æ¶
  - å‘é‡åŠ æ³•ç¤ºä¾‹ï¼ˆå¯æ‰©å±•æ›´å¤šç®—å­ï¼‰

#### ğŸ¤– æ¨¡å‹æ”¯æŒ

- âœ… **Qwen2** ç³»åˆ—æ¨¡å‹ (0.5B, 1.5B, 7B)
  > :skull: 7B æœªè¿›è¡Œæµ‹è¯•
  - å®Œæ•´çš„æ¨¡å‹å®ç°
  - æƒé‡åŠ è½½ä¸è½¬æ¢
  - é‡åŒ–æ”¯æŒ (FP16)

### ğŸ”® è®¡åˆ’åŠŸèƒ½ (è¯¦è§ [ROADMAP.md](./ROADMAP.md))

- :construction: é¡¹ç›®ä»£ç é‡æ„ä¸­(**é‡æ„ç›®æ ‡ç±»ä¼¼ nano-vllm**)
- ğŸ”„ å¼ é‡å¹¶è¡Œ (Tensor Parallelism)
- ğŸ”„ æµæ°´çº¿å¹¶è¡Œ (Pipeline Parallelism)
- ğŸ”„ Flash Attention é›†æˆ
- ğŸ”„ PagedAttention
- ğŸ”„ æ¨æµ‹è§£ç  (Speculative Decoding)
- ğŸ”„ é‡åŒ–æ”¯æŒ (INT8/INT4)
- ğŸ”„ æ›´å¤šæ¨¡å‹æ¶æ„

## ğŸš€ å¿«é€Ÿå¼€å§‹

> ğŸ’¡ **æ–°æ‰‹æ¨è**: æŸ¥çœ‹è¯¦ç»†çš„ [å¿«é€Ÿå…¥é—¨æŒ‡å—](./docs/QUICKSTART.md) è·å–å®Œæ•´æ•™ç¨‹å’Œå¸¸è§é—®é¢˜è§£ç­”ã€‚

### ç¯å¢ƒè¦æ±‚

- Python 3.10-3.12
- CUDA 11.8+ (ç”¨äº GPU åŠ é€Ÿ)

### å®‰è£…

1. **å…‹éš†ä»“åº“**

```bash
git clone https://github.com/tom-jerr/MiniInfer .git
cd MiniInfer
```

2. **å®‰è£…ä¾èµ–**

ä½¿ç”¨ PDM:

```bash
pip install pdm
pdm install
```

3. **æ„å»º CUDA æ‰©å±•** (å¯é€‰)

```bash
pdm run build-ext
pdm run build-ext-test  # æµ‹è¯•æ‰©å±•
```

### åŸºç¡€ä½¿ç”¨

#### 1. å•ä¸ªè¯·æ±‚æ¨ç†

```bash
# ä½¿ç”¨ç®€å•ç”Ÿæˆ (æ—  KV Cache)
pdm main
# æˆ–ä½¿ç”¨å¸¦ KV Cache ç‰ˆæœ¬
pdm main-with-kvcache
```

#### 2. æ‰¹å¤„ç†æ¨ç†

```bash
pdm batch-main
```

#### 3. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pdm test

# è¿è¡Œç‰¹å®šæµ‹è¯•
pdm test --fun gqa # ä¼šæµ‹è¯• unittests/test_gqa.py
```

### ä½¿ç”¨ç¤ºä¾‹

:construction: æ­£åœ¨æ–½å·¥

## ğŸ—ï¸ æ¶æ„

### é¡¹ç›®ç»“æ„

:construction: æ­£åœ¨æ–½å·¥

### æ ¸å¿ƒè®¾è®¡

:construction: æ­£åœ¨æ–½å·¥

## ğŸ§ª æµ‹è¯•

é¡¹ç›®åŒ…å«å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pdm run test

# è¿è¡Œç‰¹å®šæµ‹è¯•
# è¿è¡Œç‰¹å®šæµ‹è¯•
pdm test --fun gqa # ä¼šæµ‹è¯• unittests/test_gqa.py
```

## ğŸ—ºï¸ å¼€å‘è·¯çº¿

æŸ¥çœ‹ [ROADMAP.md](./ROADMAP.md) äº†è§£è¯¦ç»†çš„å¼€å‘è®¡åˆ’å’Œè¿›åº¦ã€‚

### è¿‘æœŸç›®æ ‡ (Q4 2025 - Q1 2026)

- [ ] Flash Attention é›†æˆ
- [ ] PagedAttention å®ç°
- [ ] å¼ é‡å¹¶è¡ŒåŸºç¡€æ”¯æŒ

### ä¸­æœŸç›®æ ‡ (Q2-Q3 2026)

- [ ] å®Œæ•´çš„ Tensor Parallelism
- [ ] Pipeline Parallelism
- [ ] INT8 é‡åŒ–æ”¯æŒ

## ğŸ“š æ–‡æ¡£

- **[å¿«é€Ÿå…¥é—¨æŒ‡å—](./docs/QUICKSTART.md)** - 5 åˆ†é’Ÿä¸Šæ‰‹æ•™ç¨‹ï¼ŒåŒ…å«å¸¸è§é—®é¢˜è§£ç­”
- **[å¼€å‘è·¯çº¿å›¾](./ROADMAP.md)** - è¯¦ç»†çš„åŠŸèƒ½è§„åˆ’å’Œå¼€å‘è¿›åº¦
- **[è´¡çŒ®æŒ‡å—](./CONTRIBUTING.md)** - å¦‚ä½•ä¸ºé¡¹ç›®åšè´¡çŒ®
- **[æ›´æ–°æ—¥å¿—](./CHANGELOG.md)** - ç‰ˆæœ¬å†å²å’Œå˜æ›´è®°å½•
- **[æ¿€æ´»å‡½æ•°æ¥å£æ–‡æ¡£](./docs/activation_interface.md)** - æ¿€æ´»å‡½æ•°ä½¿ç”¨è¯´æ˜

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åœ¨å¼€å‘è¿‡ç¨‹ä¸­å‚è€ƒäº†ä»¥ä¸‹ä¼˜ç§€é¡¹ç›®å’Œèµ„æºï¼š

### å¼€æºé¡¹ç›®

- **[tiny-llm](https://github.com/skyzh/tiny-llm)** - æœ€åˆçš„é¡¹ç›®æ¡†æ¶ä»£ç å‚è€ƒ
- **[nano-vllm](https://github.com/GeeeekExplorer/nano-vllm)** - é‡æ„åé¡¹ç›®æ¡†æ¶ä»£ç å‚è€ƒ
- **[vLLM](https://github.com/vllm-project/vllm)** - é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“ï¼ŒPagedAttention å’Œ Continuous Batching çš„åˆ›æ–°å®ç°ç»™äº†æˆ‘ä»¬å¾ˆå¤§å¯å‘

### ç†è®ºåŸºç¡€

- **Attention Is All You Need** - Transformer æ¶æ„çš„å¥ åŸºè®ºæ–‡
- **GQA: Training Generalized Multi-Query Transformer Models** - Grouped Query Attention çš„è®¾è®¡æ€æƒ³
- **Efficient Memory Management for Large Language Model Serving with PagedAttention** - vLLM çš„æ ¸å¿ƒæŠ€æœ¯è®ºæ–‡

### ç‰¹åˆ«è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºå¼€æº LLM ç”Ÿæ€ç³»ç»Ÿåšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç ”ç©¶è€…ã€‚æœ¬é¡¹ç›®ä½œä¸ºå­¦ä¹ æ€§è´¨çš„å®ç°ï¼Œæ—¨åœ¨å¸®åŠ©æ›´å¤šäººç†è§£ç°ä»£ LLM æ¨ç†ç³»ç»Ÿçš„å·¥ä½œåŸç†ã€‚

å¦‚æœæœ¬é¡¹ç›®çš„ä»£ç ä¸­æœ‰ä»»ä½•å‚è€ƒæœªæ˜ç¡®æ ‡æ³¨æ¥æºï¼Œè¯·è”ç³»æˆ‘ä»¬ï¼Œæˆ‘ä»¬ä¼šç«‹å³è¡¥å……è¯´æ˜ã€‚

## ğŸ“š ç›¸å…³èµ„æº

- [Transformer è®ºæ–‡](https://arxiv.org/abs/1706.03762)
- [GQA è®ºæ–‡](https://arxiv.org/abs/2305.13245)
- [vLLM è®ºæ–‡](https://arxiv.org/abs/2309.06180)
- [Qwen2 æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2407.10671)

## ğŸ“§ è”ç³»æ–¹å¼

- ä½œè€…: lzy
- Email: tomlzy213@gmail.com
- GitHub: [@tom-jerr](https://github.com/tom-jerr)

---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ï¸ Starï¼**

Made with â¤ï¸ by [tom-jerr](https://github.com/tom-jerr)

</div>
